## Case Study Description
#### 1. ImageProcessing_ImproveQuality.ipynb :
As of July 2023, both Apple and Samsung lead the smartphone industry worldwide, with a combined 52.61% of the total market share. As the main feature that must be present on today's smartphones, Apple and Samsung are competing to create camera technology so you can capture your best photo even in the low light condition.
  - In September 2019, Apple introduced Deep Fusion technology (via the iPhone 11 series) to tackle the challenge. Its upgrade, named Photonic Engine, was introduced in September 2022 via the new iPhone 14 series.
  - In February 2023, Samsung introduced Adaptive Tetra-squared Pixel Sensor technology with the Samsung S23 series as a counter-solution to a similar problem, promising excellent bright photo results from dark-toned images.
At its core, both technologies work by combining several adjacent pixels into a single pixel, using a Max Pooling operation. In this case, you are challenged to replicate the concept (brighten dark-toned photos), and then compare the result with another approach, i.e., Contrast Limited Adaptive Histogram Equation (CLAHE).

#### 2. TransferLearning_MultiClassification.ipynb
   A new robotic facility located in East Kalimantan, near the Titik Nol Ibu Kota Negara (IKN) Indonesia, asks you to create a Computer Vision model for their new droid (robot) products. The company requests you to teach the robot how to read a sequence of numbers. You suddenly realize that the first stage is to let the robot correctly identify each individual digit (0-9). However, since the prototype announcement date was hastened, your deadline is very tight: you only have less than 1 week to complete the job. As a professional AI developer, you keep calm and know that you can exploit the Transfer Learning method to solve this problem efficiently.
   As a basic dataset in most of Computer Vision tasks, Modified National Institute of Standards and Technology (MNIST) database contains 10 handwritten digits. All of them are in the grayscale (1-channel). Torchvision, a sub-library of PyTorch, has dozens of pre-trained models that you can easily choose from. All of these models were originally trained on the ImageNet dataset, which contains millions of RGB (3-channel) images and 1,000 classes. For simplicity, let choose Resnet18, DenseNet121, and Vision Transformer (ViT) as baseline, state-of-the-art models to test the image classification performance. Your complete tasks are as follows.
- Pick DenseNet as your first model to experiment with, then change the number of neurons in the first and last layers (since the ImageNet has 1,000 classes, while MNIST only has 10 classes; both are also come with different image size and channel).
- Define hyperparameters and train the model (all layers are trainable).
- Plot the model performance, for both training and validation results.
- Try to freeze (layers are non-trainable) some parts of layers: (1) "denseblock1", (2) "denseblock1" and "denseblock2". These will be two separate models.
- Retrain each model, plot its performance, and examine the difference.
